---
title: "Candy_report"
author: "Neil"
date: "2022-08-02"
output:
  html_document: default
  word_document: default
---
# 1. Brief Introduction to the Dataset

The data is in three parts, one file for each year 2015 - 2017. Sadly none of the datasets agree on how they are set out - many of the columns are different. It broadly records peoples experience of going trick or treating and their ratings (Despair, Joy or Meh) for various types of candy handed out. Also collected are whether they are going trick or treating, age, gender etc. 

# 2. List of Assumptions

1. I have tried to leave in as much data as possible. I did wonder if I should trim the data down to the minimum required for the tasks but ended up keeping in every column which existed in at least two of the three datasets. UPDATE - I ended up trimming down to bare minimum due to performance issues with my PC. But the cleaning script is still written to leave these in up until the last line before the merge which chops out all extra columns.
2. I have made some assumptions around spelling mistakes and amalgamating these with what I thought must have been meant. e.g. boxo_raisins == box_o_raisins, sweetums_a_friend_to_diabetes = sweetums etc. I have labelled these as I go
3. There are a myriad of responses in the country column. This should REALLY be a drop down on the questionnaire/survey. I have amalgamated as logically as possible. Outliers were tied to NA values. Could these have been labelled "smart_answer" or something like that?
4. Task 8 - should possibly be filtered there are total counts of 0 and 1 in there which do not accurately report anything at all. Perhaps should be filtered for total_count > 1 at the least.

# 3. Steps to clean data

### Libraries and load data
```{r,eval=FALSE}
# Libraries ---------------------------------------------------------------

library(tidyverse)
library(readxl)
library(here)
library(janitor)

# Load in Raw Data --------------------------------------------------------

candy_2015 <- read_excel(here("raw_data/boing-boing-candy-2015.xlsx"))
candy_2016 <- read_excel(here("raw_data/boing-boing-candy-2016.xlsx"))
candy_2017 <- read_excel(here("raw_data/boing-boing-candy-2017.xlsx"))
```

## 3.1 Pre-join Cleaning

### Clean column names and first look at the data

First Look at Data  

I used glimpse(), summary(), view(), skimr::skim() on each to get an idea of the datasets

```{r}
# Clean Column Names ------------------------------------------------------

# lets pass through clean_names to get rid of punctuation and bad column names
candy_2015_clean <- candy_2015 %>% 
  clean_names()
candy_2016_clean <- candy_2016 %>% 
  clean_names()
candy_2017_clean <- candy_2017 %>% 
  clean_names()

# commented these out to avoid lots of code output
#names(candy_2015_clean)
#names(candy_2016_clean)
#names(candy_2017_clean)
# these look better
```

Order of Operations:
Get large pivot data the same for all 3 datasets
perform pivot on all three
then investigate other columns

### Pivot longer and some cleaning beforehand
```{r}
# let first start with all the columns between "100_grand_bar" and 
# "york peppermint butter" these are out pivot to longer columns
candy_2015_clean <- candy_2015_clean %>% 
  rename("100_grand_bar" = "x100_grand_bar") %>% 
  relocate(butterfinger, .after = bubble_gum) %>% 
  relocate(necco_wafers, .after = minibags_of_chips)
           
candy_2016_clean <- candy_2016_clean %>% 
  rename("100_grand_bar" = "x100_grand_bar")

# 2017 data required a q1_, q2_ etc removed from the column names
candy_2017_clean <- candy_2017_clean %>% 
  rename_with( ~ str_remove(., pattern = "q[0-90-9]+_"))


# pivot longer on all three datasets for the candy and rating columns

candy_2015_long <- candy_2015_clean %>% 
  pivot_longer(`100_grand_bar`:york_peppermint_patties, 
               names_to = "candy_type", 
               values_to = "candy_rating")

candy_2016_long <- candy_2016_clean %>% 
  pivot_longer(`100_grand_bar`:york_peppermint_patties, 
               names_to = "candy_type", 
               values_to = "candy_rating")

candy_2017_long <- candy_2017_clean %>% 
  pivot_longer(`100_grand_bar`:york_peppermint_patties, 
               names_to = "candy_type", 
               values_to = "candy_rating")
```


### Cleaning columns - dropping NA columns and others only in 1 dataset

Pivots look good lets look through each dataset and see which columns are required and which can go. In this decision I am thinking of the upcoming join of the three data frames. It looks like this will have to be a bind_rows function I will hope to keep each column that's in at least 2 of the 3 data frames.

```{r}
# 2015 Table

# lets work out how many NA's are across all columns and sort by highest
NA_2015 <- candy_2015_long %>%
  summarise(across(.fns = ~ sum(is.na(.x)))) %>% 
  pivot_longer(cols = everything(), 
               names_to = "old_column_name", 
               values_to = "count_of_NA") %>% 
  arrange(desc(count_of_NA))

# lets drop these 9 full NA columns - no use to us
candy_2015_long <- candy_2015_long %>% 
  select(-fill_in_the_blank_taylor_swift_is_a_force_for, 
         -starts_with("please_estimate_the_degrees_of_"))

# 2016

# lets work out how many NA's are across all columns and sort by highest
NA_2016 <- candy_2016_long %>%
  summarise(across(.fns = ~ sum(is.na(.x)))) %>% 
  pivot_longer(cols = everything(), 
               names_to = "old_column_name", 
               values_to = "count_of_NA") %>% 
  arrange(desc(count_of_NA))

# lets drop this full NA column - no use to us
candy_2016_long <- candy_2016_long %>% 
  select(-york_peppermint_patties_ignore)

# 2017

# lets work out how many NA's are across all columns and sort by highest
NA_2017 <- candy_2017_long %>%
  summarise(across(.fns = ~ sum(is.na(.x)))) %>% 
  pivot_longer(cols = everything(), 
               names_to = "old_column_name", 
               values_to = "count_of_NA") %>% 
  arrange(desc(count_of_NA))

# lets drop columns x114 which is ambigous and very nearly empty as well as the
# media columns - these are also nearly empty and are not in the other datasets
candy_2017_long <- candy_2017_long %>% 
  select(-x114, 
         -starts_with("media"))
```

Ok lets recap. We have removed the easy columns so far - the full NA's and the columns with very little data. Candy_2017_long has fewer columns than the others - lets use this as a template for the other data frame columns and try to get our column names matching to prepare data for a future bind_rows.

### Cleaning columns - names and order, 2016/2017

```{r}
# lets get 2016 into shape - change col names to agree with 2017
candy_2016_long <- candy_2016_long %>% 
  rename(
    id = timestamp,
    going_out = are_you_going_actually_going_trick_or_treating_yourself,
    gender = your_gender,
    age = how_old_are_you,
    country = which_country_do_you_live_in,
    state_province_county_etc = which_state_province_county_do_you_live_in,
    joy_other = please_list_any_items_not_included_above_that_give_you_joy,
    despair_other = please_list_any_items_not_included_above_that_give_you_despair,
    other_comments = please_leave_any_witty_snarky_or_thoughtful_remarks_or_comments_regarding_your_choices,
    day = which_day_do_you_prefer_friday_or_sunday,
    dress = that_dress_that_went_viral_a_few_years_back_when_i_first_saw_it_it_was,
    guess_mints = guess_the_number_of_mints_in_my_hand,
    favourite_font = what_is_your_favourite_font) 

#Lets change the really long cilumn names about the celebrities
candy_2016_long <- candy_2016_long %>% 
  rename_with( ~ str_replace(., pattern = "please_.*celebrities_", replacement = "separation_"))

# reorder to agree more with 2017
candy_2016_long <- candy_2016_long %>%
relocate(dress, day, candy_type, candy_rating, .after = other_comments)

# drop columns which don't appear elsewhere, have little values - i have
# detailed this in the assumptions 
candy_2016_long <- candy_2016_long %>%
  select(-(23:24))

#names(candy_2016_long) # looks good

# lets tweak 2017 in line with 2016 above

candy_2017_long <- candy_2017_long %>% 
  rename(id = internal_id) %>% 
  select(-click_coordinates_x_y) %>% # only in this 1 data frame
  mutate(guess_mints = NA, betty_or_veronica = NA, favourite_font = NA,
         separation_jk_rowling = NA, separation_jj_abrams = NA, separation_beyonce = NA, separation_bieber = NA,            separation_kevin_bacon = NA, separation_francis_bacon_1561_1626 = NA) # add in columns that are in other 2

names(candy_2016_long) == names(candy_2017_long) # columns all match!
```

Ok so we have candy_2016 and candy_2017 matching perfectly for a bind_rows. lets work on 2015 - a bit more to do here

### Cleaning columns in year 2015

```{r}
# OK time for 2015 to match the other two years
candy_2015_long <- candy_2015_long %>% 
  rename(
    id = timestamp,
    age = how_old_are_you,
    going_out = are_you_going_actually_going_trick_or_treating_yourself,
    other_comments = please_leave_any_remarks_or_comments_regarding_your_choices,
    joy_other = please_list_any_items_not_included_above_that_give_you_joy,
    despair_other = please_list_any_items_not_included_above_that_give_you_despair,
    guess_mints = guess_the_number_of_mints_in_my_hand,
    favourite_font = what_is_your_favourite_font,
    day = which_day_do_you_prefer_friday_or_sunday,
    dress = that_dress_that_went_viral_early_this_year_when_i_first_saw_it_it_was)

# rename large column names
candy_2015_long <- candy_2015_long %>% 
  rename_with( ~ str_replace(., pattern = "please_.*celebrities_", replacement = "separation_"))

# reorder to agree more with others
candy_2015_long <- candy_2015_long %>%
  relocate(dress, day, candy_type, candy_rating, .after = other_comments)

# delete columns not in other datasets
candy_2015_long <- candy_2015_long %>%
  select(-if_you_squint_really_hard_the_words_intelligent_design_would_look_like,
         - fill_in_the_blank_imitation_is_a_form_of,
         - sea_salt_flavored_stuff_probably_chocolate_since_this_is_the_it_flavor_of_the_year,
         -check_all_that_apply_i_cried_tears_of_sadness_at_the_end_of)

# add in columns in line with others - these will need to be NA as theres no data
# only alternative would be to lose all data from other tables 
candy_2015_long <- candy_2015_long %>%
  mutate(gender = NA, country = NA, state_province_county_etc = NA)

# final reorder to agree more with others
candy_2015_long <- candy_2015_long %>%
  relocate(going_out, gender, .after = id) %>% 
  relocate(country, state_province_county_etc, joy_other, despair_other, 
           other_comments, .after = age)

names(candy_2015_long) == names(candy_2016_long)

# So we now have 3 datasets ready to be bound together
# Then we can look at the columns like country that need cleaned up

# lets mutate the id fields into characters for the sake of the join
candy_2015_long <- candy_2015_long %>%
  mutate(id = as.character(id))
candy_2016_long <- candy_2016_long %>%
  mutate(id = as.character(id))
candy_2017_long <- candy_2017_long %>%
  mutate(id = as.character(id))
```

### Further data cleanse 
Performed here for performance - my PC is slowing down so much with all this data kept. Having done the tasks with the full dataset (slowly!) I've come back to tidy up - these columns are not needed and can always be added at a later date if required. All that time wasted but nevermind!

```{r}
candy_2015_long <- candy_2015_long %>% 
select(-(state_province_county_etc:day)) %>% 
  select(-(guess_mints:separation_francis_bacon_1561_1626))
candy_2016_long <- candy_2016_long %>% 
  select(-(state_province_county_etc:day)) %>% 
  select(-(guess_mints:separation_francis_bacon_1561_1626))
candy_2017_long <- candy_2017_long %>% 
  select(-(state_province_county_etc:day)) %>% 
  select(-(guess_mints:separation_francis_bacon_1561_1626))
```

### Join

Lets join the tables here with a bind_rows - easy now that weve got the columns in order. Also add an id column to let us differentiate the year the data comes from.

```{r}
candy_combined <- bind_rows(candy_2015_long, 
                            candy_2016_long, 
                            candy_2017_long, 
                            .id = "year") 
# last line adds a column to let us know original table data is from
```

## 3.2 Column Cleaning

Lets go through the columns one by one to see what needs done

### candy_type column cleaning
```{r}
#table(candy_combined["candy_type"]) commented out to avoid massive output

# OK so there are a few obvious duplicates with slightly different names
# There are some slightly the same but ambiguous - these will be left

candy_combined <- candy_combined %>% 
  mutate(candy_type = recode(candy_type,
  "anonymous_brown_globs_that_come_in_black_and_orange_wrappers_a_k_a_mary_janes" = "mary_janes"),
  candy_type = recode(candy_type,"bonkers_the_candy" = "bonkers"),
  candy_type = recode(candy_type,"boxo_raisins" = "box_o_raisins"),
  candy_type = recode(candy_type,"licorice_yes_black" = "licorice"),
  candy_type = recode(candy_type,"sweetums_a_friend_to_diabetes" = "sweetums"))
```

### country column cleaning
```{r}
## Cleaning country column ------------------------------------------------

# count(candy_combined, country)
# table(candy_combined["country"]) # look at dirty column 'country' eek

# get a few easy ones with regex
candy_combined <- candy_combined %>% 
  mutate(country = if_else(grepl("(?i)usa+", country),"USA",country)) %>% 
  mutate(country = if_else(grepl("(?i)united s+", country),"USA",country)) %>% 
  mutate(country = if_else(grepl("(?i)amer", country),"USA",country)) %>% 
  mutate(country = if_else(grepl("(?i)stat", country),"USA",country))

#make vectors of USA outliers and some to change to NA values
usa_outliers = c("Alaska", "California", "EUA", "Merica", "Murica", "murrika",
                 "New Jersey", "New York", "North Carolina", "Pittsburgh", 
                 "The Yoo Ess of Aaayyyyyy", "Trumpistan", "U S", "u s a", "u.s.",
                 "U.s.", "U.S.", "u.s.a.", "U.S.A.", "UD", "us", "Us", "US", "US of A",
                 "USSA", "'merica")
change_to_NA = c(1, 30.0, 32, 35, 44.0, 45, 45.0, 46, 47.0, 51.0, 54.0)
change_to_NA2 = c("30.0", "44.0", "45.0", "47.0", "51.0", "54.0")
silly_values = c(
  "A tropical island south of the equator", "A", "Atlantis",
  "Canae", "cascadia ", "Cascadia", "Denial", "Earth", "Fear and Loathing", 
  "god's country", "I don't know anymore", "insanity lately", 
  "there isn't one for old men", "soviet canuckistan", "Narnia", "Neverland",
  "one of the best ones", "See above", "Somewhere", 
  "Subscribe To Dm4uz3 On Youtube", "The republic of Cascadia", "this one", 
  "Europe", " Cascadia", "Cascadia ", " Subscribe To Dm4uz3 On Youtube",
  "Subscribe To Dm4uz3 On Youtube ")

# use the vectors above 
candy_combined <- candy_combined %>%
  mutate(country = if_else(country %in% usa_outliers ,
                           "USA", country)) 

candy_combined <- candy_combined %>%
  mutate(country = if_else(country %in% silly_values|
                             country %in% change_to_NA|
                             country %in% change_to_NA2, 
                           NA_character_, country)) %>% 
  mutate(country = str_to_title(country)) # change to title case to help

# recode anything else
candy_combined <- candy_combined %>%
  mutate(country = recode(country, "The Netherlands" = "Netherlands"),
         country = recode(country, "Can" = "Canada"),
         country = recode(country, "Canada`" = "Canada"),
         country = recode(country, "Endland" = "United Kingdom"),
         country = recode(country, "England" = "United Kingdom"),
         country = recode(country, "England" = "United Kingdom"),
         country = recode(country, "Scotland" = "United Kingdom"),
         country = recode(country, "España" = "Spain"),
         country = recode(country, "U.k." = "United Kingdom"),
         country = recode(country, "Uk" = "United Kingdom"),
         country = recode(country, "United Kindom" = "United Kingdom"))

#table(candy_combined["country"]) # much better!
```

### age column cleaning
```{r, eval=FALSE}
## Cleaning age column -----------------------------------------------------

# oldest person ever was 122. lets take out everything above that as NA
# lets keep in the 0 values - technically this could be babies in a pram?

# change the column from a character to numeric
candy_combined <- candy_combined %>%
  mutate(age = as.numeric(age))

# clean out values bigger than 122 - oldest ever person
candy_combined <- candy_combined %>%
  mutate(age = ifelse(age>122, NA, age))
```

### year column cleaning
```{r}
## Cleaning year column ----------------------------------------------------

# change the id value brought over from the bind rows to an actual year
# alter the column to be numeric rather than character
candy_combined <- candy_combined %>%
  mutate(year = recode(year, "1" = "2015"),
         year = recode(year, "2" = "2016"),
         year = recode(year, "3" = "2017"),
         year = as.numeric(year))
```

## 3.3 Write Clean Data
```{r}
# Write our data to candy_clean.csv ---------------------------------------

candy_combined %>%
write_csv(here("clean_data/candy_clean.csv"))

```


# 4. Answers to Task Brief Questions

### Load Libraries and data
```{r}
library(readr)
library(tidyverse)
library(here)

candy_clean <- read_csv(here("clean_data/candy_clean.csv"))
```

### Task 1 What is the total number of candy ratings given across the three years.

```{r}
# This would be the number of rows in candy_rating != NA
candy_clean %>% 
  drop_na(candy_rating) %>% 
  nrow()

  # total ratings - 767302

```

### Task 2 What was the average age of people who are going out trick or treating?

```{r}

# filter for Yes to going out then average the age column
candy_clean %>% 
  filter(going_out == "Yes") %>% 
  summarise(avg_age = mean(age, na.rm = TRUE))

# Average_age is 35.22
```

### Task 3 What was the average age of people who are not going trick or treating?

```{r}

# filter for No to going out then average the age column
candy_clean %>% 
   filter(going_out == "No") %>% 
summarise(avg_age = mean(age, na.rm = TRUE))

# Average age is 39.26
```

### Task 4 For each of joy, despair and meh, which candy bar received the most of these ratings?

```{r}
# Despair
candy_clean %>% 
  group_by(candy_type) %>% 
  count(candy_rating, name = "count_of_rating") %>% 
  filter(candy_rating == "DESPAIR") %>% 
  ungroup() %>% 
  arrange(desc(count_of_rating)) %>% 
  slice_max(count_of_rating, n = 1)

# Answer : broken_glow_stick

# Joy
candy_clean %>% 
  group_by(candy_type) %>% 
  count(candy_rating, name = "count_of_rating") %>% 
  filter(candy_rating == "JOY") %>% 
  ungroup() %>% 
  arrange(desc(count_of_rating)) %>% 
  slice_max(count_of_rating, n = 1)

# Answer : any_full_sized_candy_bar

# Meh
candy_clean %>% 
  group_by(candy_type) %>% 
  count(candy_rating, name = "count_of_rating") %>% 
  filter(candy_rating == "MEH") %>% 
  ungroup() %>% 
  arrange(desc(count_of_rating)) %>% 
  slice_max(count_of_rating, n = 1)

# Answer : lollipops
```

### Task 5 How many people rated Starburst as despair?

```{r}
# filter for starburst and despair then count the rows
candy_clean %>% 
  filter(candy_type == "starburst" & 
           candy_rating == "DESPAIR") %>% 
  nrow()

# 1990 people thought starburst was despair-worthy
```

#### Change the dataset for new ordering system

```{r}
# add on a column which gives each column a score according to this new scoring method
candy_clean <- candy_clean %>% 
 mutate(candy_rating_new_system = case_when ( candy_rating == "DESPAIR" ~ -1,
                                              candy_rating == "JOY" ~ 1,
                                              TRUE ~ 0
 ))
```


### Task 6 What was the most popular candy bar by this rating system for each gender in the dataset

```{r}
# Filter for female gender, group by candy type then assign each a value
# according to the sum of the new voting criteria, arrange and slice top hit
candy_clean %>% 
  filter(gender == "Female") %>% 
  group_by(candy_type) %>% 
  summarise(new_rating_total = sum(candy_rating_new_system)) %>% 
  arrange(desc(new_rating_total)) %>% 
  slice_head(n=1)
# Female answer : Any full sizer candy bar - 875 count

# Filter for male gender, group by candy type then assign each a value
# according to the sum of the new voting criteria, arrange and slice top hit
candy_clean %>% 
  filter(gender == "Male") %>% 
  group_by(candy_type) %>% 
  summarise(new_rating_total = sum(candy_rating_new_system)) %>% 
  arrange(desc(new_rating_total)) %>% 
  slice_head(n=1)

# Male answer : Any full sizer candy bar - 1584 count

```

### Task 7 What was the most popular candy bar in each year?

```{r}
# filter for year, group by candy type, sum the new rating system for each 
# candy type, arrange by highest and slice the top hit
candy_clean %>% 
  filter(year == 2015) %>% 
  group_by(candy_type) %>% 
  summarise(new_rating_total = sum(candy_rating_new_system)) %>% 
  arrange(desc(new_rating_total)) %>% 
  slice_head(n=1)

candy_clean %>% 
  filter(year == 2016) %>% 
  group_by(candy_type) %>% 
  summarise(new_rating_total = sum(candy_rating_new_system)) %>% 
  arrange(desc(new_rating_total)) %>% 
  slice_head(n=1)

candy_clean %>% 
  filter(year == 2017) %>% 
  group_by(candy_type) %>% 
  summarise(new_rating_total = sum(candy_rating_new_system)) %>% 
  arrange(desc(new_rating_total)) %>% 
  slice_head(n=1)


```

### Task 8 What was the most popular candy bar by this rating for people in US, Canada, UK, and all other countries?

```{r}
# filter out the country NA values, group by country (put other countries into "other" and candy type, summarise new rating system by country and candy type arrange the total rating for each candy type BY GROUP slice the head for each group - return top candy type per country

candy_clean %>% 
  filter(!is.na(country)) %>% 
  mutate(country = if_else(country %in% c("Usa", "Canada", "United Kingdom"), 
                           country, 
                           "Other")) %>%
  group_by(country, candy_type) %>% 
  summarise(new_rating_total = sum(candy_rating_new_system)) %>% 
  arrange(desc(new_rating_total), by_group = TRUE) %>% 
  slice(1)

```

# 5. Any other analysis or conclusions

Dont allow people free reign with a survey!!! Limit possible responses.

Could have written a fucntion for the repepetive tasks with multiple code chunks like q4,6,7